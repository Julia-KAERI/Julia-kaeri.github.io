---
title: "Hardware Implementation"

number-sections: true
number-depth: 2
crossref:
  chapters: false
---

NVIDIA GPU 아키텍처는 다중 스레드 스트리밍 멀티프로세서(SM)의 확장 가능한 배열을 중심으로 구축되어 있다. 호스트 CPU 의 CUDA 프로그램이 커널 그리드를 호출하면, 그리드의 블록들이 실행 가능한 용량을 가진 멀티프로세서에 할당된다. 스레드 블록의 스레드들은 하나의 멀티프로세서에서 동시에 실행되며, 여러 스레드 블록이 하나의 멀티프로세서에서 동시에 실행될 수 있다. 스레드 블록이 종료되면, 빈 멀티프로세서에서 새로운 블록이 실행된다.

멀티프로세서는 수백 개의 스레드를 동시 실행하도록 설계되었다. 이렇게 많은 스레드를 관리하기 위해 SIMT(Single-Instruction, Multiple-Thread)라는 독창적인 아키텍처를 사용하며, 이에 대해서는 [SIMT 아키텍처(SIMT Architecture)](@sec-cuda_simt_architecture) 에서 설명합니다. 명령어들은 파이프라인으로 처리되어, 단일 스레드 내의 명령어 수준 병렬성뿐만 아니라, 하드웨어의 동시 멀티스레딩을 통한 광범위한 스레드 수준 병렬성도 활용다. 하드웨어 멀티스레딩에 대한 자세한 내용은 [하드웨어 멀티스레딩(Hardware Multithreading)](#sec-cuda_hardware_multithreading)에서 설명한다. CPU 코어와 달리, 명령어는 순서대로 발행되며 브랜치 예측(branch prediction) 이나 추측 실행(speculative execution)은 없다.

[SIMT 아키텍처](#sec-cuda_simt_archtecture)와 [하드웨어 멀티스레딩](#sec-cuda_hardware_multithreading) 은 모든 디바이스에 공통적으로 적용되는 스트리밍 멀티프로세서의 아키텍처 특징을 설명합니다. 각각 [Compute Capability 5.x](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#compute-capability-5-x), [Compute Capability 6.x](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#compute-capability-6-x) 및 [Compute Capability 7.x](https://docs.nvidia.com/cuda/cuda-c-programming-guide/#compute-capability-7-x) 에 대한 세부 사항은 compute capability 5.x, 6.x, 7.x에서 제공됩니다.

NVIDIA GPU 아키텍처는 리틀 엔디언 표현을 사용한다.

</br>

## SIMT 아키텍쳐 {#sec-cuda_simt_archtecture}


</br>

## 하드웨어 멀티스레딩(Hardware Multithreading) {#sec-cuda_hardware_multithreading}