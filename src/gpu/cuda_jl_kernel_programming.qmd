---
title: "CUDA.jl 커널 프로그래밍"

number-sections: true
number-depth: 2
crossref:
  chapters: false
---

## 커널

CPU 에서 호출하고 GPU 에서 실행되는 함수를 커널(kernel) 이라고 한다. 커널은 보통의 julia 함수처럼 정의한다.

```julia
function my_kernel()
    return
end
```

커널을 실행하기 위해서는 `@cuda` 매크로를 사용한다.

```julia
@cuda my_kernel
```

위의 명령을 실행하면 `my_kernel` 함수가 컴파일되며 현재의 GPU 에서 실행된다.

</br>

`@cuda` 매크로에 `launch=false` 인자를 전달하면 컴파일만 되고 실행하지 않으며 호출 가능한 객체를 리턴한다. 

```julia
julia> k = @cuda launch=false my_kernel()
CUDA.HostKernel for my_kernel()

julia> CUDA.registers(k)
4

julia> k()
```

</br>

## 커널 입력과 출력

GPU 커널은 반환값을 가질 수 없다. 즉 항상 `return` 이거나 `return nothing` 이어야 한다. 커널과 통신하는 유일한 방법은 `CuArray` 를 쓰는 것 뿐이다.

```julia
function my_kernel(a)
    a[1] = 42
    return
end

a = CuArray{Int}(undef, 1);
@cuda my_kernel(a);
a
```
```txt
42
```

</br>

## 커널 구동 설정과 인덱싱

`@cuda` 를 통해 커널을 구동하면 단일 스레드만 시작되므로 그다지 유용하지 않다. @cuda 에 대한 `threads` 및 `blocks` 키워드 인수를 사용하면 다수의 스레드를 구동할 수 있으며, 커널 내에서는 인덱싱 내장 함수를 사용하여 각 스레드의 계산을 차별화 할 수 있다.

```julia
function my_kernel(a)
    i = threadIdx().x
    a[i] = 42
    return
end

a = CuArray{Int}(undef, 5);
@cuda threads=length(a) my_kernel(a);
a
```

```txt
5-element CuArray{Int64, 1, CUDA.DeviceMemory}:
 42
 42
 42
 42
 42
```

위에 표시된 대로, CUDA C 의 `threadIdx` 등의 값은 `x`, `y`, `z` 필드가 있는 `NamedTuple` 을 반환하는 함수로 사용할 수 있다. 이런 내장 함수는 1 부터 시작하는 인덱스를 반환한다.

</br>

## 커널 컴파일 요건

사용자 정의 커널이 작동하기 위해서는 어떤 요건을 충족해야 한다.

- 메모리는 GPU에서 접근 가능해야 한다. 이는 `CuArray` 등을 사용하여 강제할 수 있다. 사용자 지정 구조체는 해당 [튜토리얼](https://cuda.juliagpu.org/stable/tutorials/custom_structs/)에서 설명한 대로 이식할 수 있다.

- 런타임 디스패치는 불가하며 모든 함수 호출은 컴파일 타임에 결정되어야 합니다. 여기서 런타임 디스패치는 완전히 특정되지 않은 함수에 의해 도입될 수도 있다는 점에 유의해야 한다. [Julia 매뉴얼](https://docs.julialang.org/en/v1/manual/performance-tips/#Be-aware-of-when-Julia-avoids-specializing) 을 참고하고 다음 예를 보자. 

```julia
function my_inner_kernel!(f, t) # does not specialize
    t .= f.(t)
end

function my_outer_kernel(f, a)
    i = threadIdx().x
    my_inner_kernel!(f, @view a[i, :])
    return nothing
end

a = CUDA.rand(Int, (2,2))
id(x) = x

@cuda threads=size(a, 1) my_outer_kernel(id, a)
```

마지막 줄 실행에서 에러가 발생하는데 이는 아래와 같이 회피 할 수 있다.

```julia
function my_inner_kernel!(f::F, t::T) where {F,T}
    t .= f.(t)
end

function my_outer_kernel(f, a)
    i = threadIdx().x
    my_inner_kernel!(f, @view a[i, :])
    return nothing
end

a = CUDA.rand(Int, (2,2))

id(x) = x

@cuda threads=size(a, 1) my_outer_kernel(id, a)
```

단지 첫번째 함수 `my_inner_kernel!` 의 인자의 함수가 파라미터로 특정되었을 뿐이다.

</br>

## 동기화 (Synchronization)

블록에서 스레드를 동기화하려면 `sync_threads()` 함수를 사용한다. predicate 를 취하는 보다 고급 변형도 사용 가능하다.

- `sync_threads_count(pred)` : `pred` 가 `true` 인 스레드의 갯수를 반환한다.

- `sync_threads_and(pred)` : 모든 스레드에서 `pred` 가 참이면 `true` 를 반환한다.

- `sync_threads_or(pred)` : 어떤 스레드에서 `pred` 가 참이면 `true` 를 반환한다.

여러 스레드 동기화 장벽을 유지하려면 장벽을 식별하는 정수 인수를 취하는 `barrier_sync` 함수를 사용한다.

워프에서 레인을 동기화하려면 `sync_warp()` 함수를 사용합니다. 이 함수는 참여할 레인을 선택하는 마스크를 취합니다(기본값은 `FULL_MASK`).

실행 장벽이 아닌 메모리 장벽만 필요한 경우 펜스 내장 함수를 사용합니다.

- `threadfence_block` : 블럭 내의 모든 쓰레드에서 메모리 정렬을 보장한다. 

- `threadfence` : 디바이스 내의 모든 쓰레드에서 메모리 정렬을 보장한다. 

- `threadfence_system` : 호스트 스레드와 peer 디바이스를 포함한 모든 스레드에서 메모리 정렬을 보장한다. 

</br>

### 공유 메모리 (Shared memory)

스레드 간 통신을 위해 공유 메모리로 백업된 디바이스 배열은 `CuStaticSharedArray` 함수를 통해 할당될 수 있다. 다음은 배열의 순서를 바꾸는 커널이다. 커널 내의 `b` 가 스레드간 통신을 위해 공유 메모리로 백업된 배열이다. 

```julia
function reverse_kernel(a::CuDeviceArray{T}) where T
    i = threadIdx().x
    b = CuStaticSharedArray(T, 2)
    b[2-i+1] = a[i]
    sync_threads()
    a[i] = b[i]
    return
end

a = cu([1,2])
@cuda threads = 2 reverse_kernel(a)
```

결과를 출력해보면 `a` 의 순서가 바뀌었음을 알 수 있다.

</br>

공유 메모리의 크기를 미리 알 수 없고 각 크기에 대해 커널을 다시 컴파일하고 싶지 않은 경우 대신 `CuDynamicSharedArray` 타입을 사용할 수 있다. 이를 위해서는 공유 메모리의 크기(바이트)를 커널에 인수로 전달해야 한다.

```julia
function reverse_kernel(a::CuDeviceArray{T}) where T
    i = threadIdx().x
    b = CuDynamicSharedArray(T, length(a))
    b[length(a)-i+1] = a[i]
    sync_threads()
    a[i] = b[i]
    return
end

a = cu([1,2,3])
@cuda threads=length(a) shmem=sizeof(a) reverse_kernel(a)
```

동적 공유 메모리를 사용하는 다수의 배열이 필요한 경우 후속 `CuDynamicSharedArray` 생성자에 공유 메모리 시작부터 바이트 단위의 오프셋을 나타내는 오프셋 매개변수를 전달한다. `@cuda` 에 대한 `shmem` 키워드는 모든 배열에서 사용하는 총 공유 메모리 양이어야 합니다.

</br>

### 경계 확인

기본적으로 `CuDeviceArray` 를 인덱싱하면 경계 검사를 수행하고 인덱스가 경계를 벗어나면 오류를 발생시키는데 이는 비용이 많이 드는 작업이므로 인덱스가 경계 내에 있다는 것이 확실하다면 일반적인 배열과 마찬가지로 `@inbounds` 를 사용 할 수 있다.

</br>

## 표준 출력

`CUDA.jl` 커널은 아직 Julia의 표준 입출력과 통합되지 않았지만 커널에서 표준 출력으로 인쇄하기 위한 몇 가지 기본 기능을 제공한다.

- `@cuprintf`: 표준 출력으로 형식화된 출력을 내보낸다.

- `@cuprint` 와 `@cuprintln` : 문자를 포함한 값을 표준 출력으로 내보낸다.

- `@cushow` : 객체의 이름과 값을 출력한다.

`@cuprintf` 매크로는 모든 형식 옵션을 지원하지 않는다. 자세한 내용은 `printf` 에 대한 NVIDIA 설명서를 참조하라. `@cuprintln` 과 `CUDA.jl` 을 통해 모든 값을 적절한 문자열 표현으로 변환하는 것이 더 편리한 경우가 많다.

```julia
julia> @cuda threads=2 (()->(@cuprintln("Hello, I'm thread $(threadIdx().x)!"); return))()
Hello, I'm thread 1!
Hello, I'm thread 2!
```

</br>
단순히 값만 출력하길 원한다면, which can be useful during debugging, `@cushow` 를 사용하라.

```julia
julia> @cuda threads=2 (()->(@cushow threadIdx().x; return))()
(threadIdx()).x = 1
(threadIdx()).x = 2
```

이것들은 매우 제한된 수의 유형만 지원한다는 점에 유의하라. 따라서 디버깅 목적으로만 사용하는 것이 좋다.