<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Programming Interface – Science &amp; Programming</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../../">
<link href="../../../src/gpu/cuda.jl/cuda_jl_array_programming.html" rel="next">
<link href="../../../src/gpu/cuda/02_programming_model.html" rel="prev">
<script src="../../../site_libs/quarto-html/quarto.js"></script>
<script src="../../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../../site_libs/bootstrap/bootstrap-442e5c93d6224642134ff5cd604ad228.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "일치 없음",
    "search-matching-documents-text": "일치된 문서",
    "search-copy-link-title": "검색 링크 복사",
    "search-hide-matches-text": "추가 검색 결과 숨기기",
    "search-more-match-text": "추가 검색결과",
    "search-more-matches-text": "추가 검색결과",
    "search-clear-button-title": "제거",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "취소",
    "search-submit-button-title": "검색",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../../styles.css">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../../index.html">
    <span class="navbar-title">Science &amp; Programming</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="탐색 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../../index.html"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link active" href="../../../src/gpu/gpu.html" aria-current="page"> 
<span class="menu-text">GPU &amp; CUDA</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../src/cpp_qt/cpp_qt.html"> 
<span class="menu-text">C++ &amp; Qt</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../src/ML/ml.html"> 
<span class="menu-text">AI &amp; ML</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../src/topics/socket.html"> 
<span class="menu-text">주제별</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../src/tools/tools.html"> 
<span class="menu-text">Tools</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../src/posts/index.html"> 
<span class="menu-text">Posts</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
    <a href="mailto:julia.kaeri@gmail.com" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-envelope"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../src/gpu/cuda/01_introduction.html">CUDA</a></li><li class="breadcrumb-item"><a href="../../../src/gpu/cuda/03_programming_interface.html">Programming Interface</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="사이드바 전환" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../src/gpu/gpu.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">GPU &amp; CUDA</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">CUDA</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../src/gpu/cuda/01_introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../src/gpu/cuda/02_programming_model.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Programming Model</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../src/gpu/cuda/03_programming_interface.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Programming Interface</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">CUDA.jl</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="토글 섹션">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../src/gpu/cuda.jl/cuda_jl_array_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CUDA.jl 배열 처리</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../src/gpu/cuda.jl/cuda_jl_kernel_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CUDA.jl 커널 프로그래밍</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../../src/gpu/cuda.jl/cuda_jl_performance_tips.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">CUDA.jl 성능 팁</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">목차</h2>
   
  <ul>
  <li><a href="#sec-cuda_nvcc_compile" id="toc-sec-cuda_nvcc_compile" class="nav-link active" data-scroll-target="#sec-cuda_nvcc_compile"><span class="header-section-number">1</span> NVCC 컴파일</a>
  <ul class="collapse">
  <li><a href="#sec-cuda_compilation_workflow" id="toc-sec-cuda_compilation_workflow" class="nav-link" data-scroll-target="#sec-cuda_compilation_workflow"><span class="header-section-number">1.1</span> 컴파일 workflow</a></li>
  <li><a href="#sec-cuda_binary_compatibility" id="toc-sec-cuda_binary_compatibility" class="nav-link" data-scroll-target="#sec-cuda_binary_compatibility"><span class="header-section-number">1.2</span> 바이너리 호환성</a></li>
  <li><a href="#sec-cuda_ptx_compatibility" id="toc-sec-cuda_ptx_compatibility" class="nav-link" data-scroll-target="#sec-cuda_ptx_compatibility"><span class="header-section-number">1.3</span> PTX 호환성</a></li>
  <li><a href="#sec-cuda_application_compatibility" id="toc-sec-cuda_application_compatibility" class="nav-link" data-scroll-target="#sec-cuda_application_compatibility"><span class="header-section-number">1.4</span> 응용 프로그램 호환성</a></li>
  <li><a href="#sec-cuda_cpp_compatibility" id="toc-sec-cuda_cpp_compatibility" class="nav-link" data-scroll-target="#sec-cuda_cpp_compatibility"><span class="header-section-number">1.5</span> C++ 호환성</a></li>
  <li><a href="#sec-cuda_64bit_compatibility" id="toc-sec-cuda_64bit_compatibility" class="nav-link" data-scroll-target="#sec-cuda_64bit_compatibility"><span class="header-section-number">1.6</span> 64 비트 호환성</a></li>
  </ul></li>
  <li><a href="#cuda-runtime" id="toc-cuda-runtime" class="nav-link" data-scroll-target="#cuda-runtime"><span class="header-section-number">2</span> CUDA Runtime</a>
  <ul class="collapse">
  <li><a href="#sec-cuda_initialization" id="toc-sec-cuda_initialization" class="nav-link" data-scroll-target="#sec-cuda_initialization"><span class="header-section-number">2.1</span> 초기화</a></li>
  <li><a href="#sec-cuda_device_memory" id="toc-sec-cuda_device_memory" class="nav-link" data-scroll-target="#sec-cuda_device_memory"><span class="header-section-number">2.2</span> 장치 메모리</a></li>
  <li><a href="#디바이스-메모리-l2-접근-관리" id="toc-디바이스-메모리-l2-접근-관리" class="nav-link" data-scroll-target="#디바이스-메모리-l2-접근-관리"><span class="header-section-number">2.3</span> 디바이스 메모리 L2 접근 관리</a></li>
  <li><a href="#sec-cuda_shared_memory" id="toc-sec-cuda_shared_memory" class="nav-link" data-scroll-target="#sec-cuda_shared_memory"><span class="header-section-number">2.4</span> 공유 메모리</a></li>
  <li><a href="#sec-cuda_distributed_shared_memory" id="toc-sec-cuda_distributed_shared_memory" class="nav-link" data-scroll-target="#sec-cuda_distributed_shared_memory"><span class="header-section-number">2.5</span> 분산 공유 메모리</a></li>
  <li><a href="#sec-cuda_page_locked_host_meory" id="toc-sec-cuda_page_locked_host_meory" class="nav-link" data-scroll-target="#sec-cuda_page_locked_host_meory"><span class="header-section-number">2.6</span> 페이지 잠금 호스트 메모리</a></li>
  <li><a href="#sec-cuda_asynchronous_concurrent_execution" id="toc-sec-cuda_asynchronous_concurrent_execution" class="nav-link" data-scroll-target="#sec-cuda_asynchronous_concurrent_execution"><span class="header-section-number">2.7</span> 비동기 동시 실행 (Asynchronous concurrent Execution)</a></li>
  <li><a href="#sec-cuda_multi_device_system" id="toc-sec-cuda_multi_device_system" class="nav-link" data-scroll-target="#sec-cuda_multi_device_system"><span class="header-section-number">2.8</span> 다중 디바이스 시스템</a></li>
  <li><a href="#sec-cuda_error_checking" id="toc-sec-cuda_error_checking" class="nav-link" data-scroll-target="#sec-cuda_error_checking"><span class="header-section-number">2.9</span> 오류 검사</a></li>
  <li><a href="#sec-cuda_call_stack" id="toc-sec-cuda_call_stack" class="nav-link" data-scroll-target="#sec-cuda_call_stack"><span class="header-section-number">2.10</span> 호출 스택</a></li>
  <li><a href="#sec-cuda_texture_and_surface_memory" id="toc-sec-cuda_texture_and_surface_memory" class="nav-link" data-scroll-target="#sec-cuda_texture_and_surface_memory"><span class="header-section-number">2.11</span> 텍스쳐와 표면 메모리</a></li>
  <li><a href="#sec-cuda_graphics_interoperability" id="toc-sec-cuda_graphics_interoperability" class="nav-link" data-scroll-target="#sec-cuda_graphics_interoperability"><span class="header-section-number">2.12</span> 그래픽 상호 운용성</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../../src/gpu/cuda/01_introduction.html">CUDA</a></li><li class="breadcrumb-item"><a href="../../../src/gpu/cuda/03_programming_interface.html">Programming Interface</a></li></ol></nav>
<div class="quarto-title">
<h1 class="title">Programming Interface</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<ul>
<li><p>CUDA C++는 C++ 프로그래밍 언어에 익숙한 사용자에게 장치에서 실행할 프로그램을 쉽게 작성할 수 있는 단순한 경로를 제공한다. C++ 언어에 대한 최소한의 확장 세트와 런타임 라이브러리로 구성되며 핵심 언어 확장은 <a href="../../../src/gpu/cuda/02_programming_model.html">Programming Model</a>에 소개되었다. 프로그래머는 커널을 C++ 함수로 정의하고 새로운 구문을 사용하여 함수가 호출될 때마다 그리드와 블록의 차원을 지정할 수 있다. 모든 확장에 대한 전체 설명은 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#c-language-extensions">C++ 언어 확장</a>에서 찾을 수 있다. 이러한 확장 중 일부를 포함하는 모든 소스 파일은 <a href="#sec-cuda_nvcc_compile">NVCC 컴파일</a>에 설명된 대로 <code>nvcc</code> 로 컴파일해야 한다.</p></li>
<li><p>런타임에 대해서는 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#cuda-c-runtime">CUDA 런타임</a> 을 참고하라. 호스트에서 실행되어 디바이스 메모리를 할당하거나 할당 해제하고, 호스트 메모리와 디바이스 메모리 간에 데이터를 전송하고, 여러 장치가 있는 시스템을 관리하는 등의 작업을 수행하는 C 및 C++ 함수를 제공한다. 런타임에 대한 전체 설명은 CUDA Reference Manumal 에서 찾을 수 있다.</p></li>
<li><p>런타임은 하위 수준 C API인 CUDA 드라이버 API 위에 구축되며 응용프로그램에서도 API 에 접근 할 수 있다. 드라이버 API는 CUDA 컨텍스트(장치의 호스트 프로세스와 유사) 및 CUDA 모듈(장치의 동적으로 로드된 라이브러리와 유사)과 같은 하위 수준 개념을 노출하여 추가적인 제어 수준을 제공한다. 대부분의 애플리케이션은 이 추가적인 제어 수준이 필요하지 않기 때문에 드라이버 API를 사용하지 않으며 런타임을 사용할 때 컨텍스트 및 모듈 관리가 암묵적이기 때문에 코드가 더 간결해진다. 런타임은 드라이버 API와 호환되기 때문에 일부 드라이버 API 기능이 필요한 대부분의 애플리케이션은 기본적으로 런타임 API를 사용하고 필요한 경우에만 드라이버 API를 사용할 수 있다. 드라이버 API는 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#driver-api">드라이버 API</a>에 소개되어 있으며 Reference manual 에 자세히 설명되어 있다.</p></li>
</ul>
<p><br></p>
<section id="sec-cuda_nvcc_compile" class="level2" data-number="1">
<h2 data-number="1" class="anchored" data-anchor-id="sec-cuda_nvcc_compile"><span class="header-section-number">1</span> NVCC 컴파일</h2>
<p>커널은 <em>PTX</em> 라고 하는 CUDA 명령어 집합 아키텍처를 사용하여 작성할 수 있으며, 이는 PTX Reference manual 에 설명되어 있다. 그러나 일반적으로 C++와 같은 고급 프로그래밍 언어를 사용하는 것이 더 효과적이다. 두 경우 모두 커널은 <code>nvcc</code> 에서 바이너리 코드로 컴파일하여 장치에서 실행해야 한다.</p>
<p><code>nvcc</code> 는 C++ 또는 PTX 코드를 컴파일하는 과정을 간소화하는 컴파일러 드라이버이다. 간단하고 익숙학 명령줄 옵션을 제공하고 다양한 컴파일 단계를 구현하는 도구 모음을 호출하여 실행한다. 이 섹션에서는 <code>nvcc</code> 워크플로 및 명령 옵션에 대해 간단히 소개한다. 전체 설명은 nvcc user manual 에서 찾을 수 있다.</p>
<p><br></p>
<section id="sec-cuda_compilation_workflow" class="level3" data-number="1.1">
<h3 data-number="1.1" class="anchored" data-anchor-id="sec-cuda_compilation_workflow"><span class="header-section-number">1.1</span> 컴파일 workflow</h3>
<section id="sec-cuda_offline_compilation" class="level4">
<h4 class="anchored" data-anchor-id="sec-cuda_offline_compilation">오프라인 컴파일</h4>
<p><code>nvcc</code> 로 컴파일된 소스 파일에는 호스트 코드(즉, 호스트에서 실행되는 코드)와 디바이스 코드(즉, 디바이스에서 실행되는 코드)가 혼합되어 포함될 수 있다. <code>nvcc</code> 의 기본 워크플로는 디바이스 코드를 호스트 코드에서 분리하는 것으로 시작하여 다음을 수행한다.</p>
<ul>
<li><p>디바이스 코드를 어셈블리 형태(PTX 코드) 및/또는 바이너리 형태(cubin 객체)로 컴파일하고,</p></li>
<li><p>Kernels에서 도입된 <code>&lt;&lt;&lt;...&gt;&gt;&gt;</code> 구문을 필요한 CUDA 런타임 함수 호출로 대체하여 호스트 코드를 수정하여 PTX 코드 및/또는 cubin 객체에서 각 컴파일된 커널을 로드하고 구동시킨다. 이 과정은 커널 실행 구성을 더 자세히 설명하는 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#execution-configuration">Execution Configuration</a>에서 다룬다.</p></li>
</ul>
<p>수정된 호스트 코드는 다른 도구를 사용하여 컴파일할 수 있는 C++ 코드로 출력되거나, 마지막 컴파일 단계에서 <code>nvcc</code> 가 호스트 컴파일러를 호출하여 직접 object code 로 출력된다. 이제 애플리케이션은 다음을 수행할 수 있다.</p>
<ul>
<li><p>컴파일된 호스트 코드에 링크(가장 일반적인 경우)하거나</p></li>
<li><p>수정된 호스트 코드(있는 경우)를 무시하고 CUDA 드라이버 API(<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#driver-api">드라이버 API</a> 참조)를 사용하여 PTX 코드 또는 cubin 객체를 로드하고 실행한다.</p></li>
</ul>
<p><br></p>
</section>
<section id="sec-cuda_jit_compilation" class="level4">
<h4 class="anchored" data-anchor-id="sec-cuda_jit_compilation">JIT 컴파일</h4>
<p>런타임에 애플리케이션에서 로드한 모든 PTX 코드는 장치 드라이버에 의해 바이너리 코드로 추가로 컴파일되는데 이를 JIT(just-in-time) 컴파일이라고 한다. JIT 컴파일은 애플리케이션 로드 시간을 늘리지만 애플리케이션이 각 새 장치 드라이버와 함께 제공되는 모든 새 컴파일러 개선 사항을 활용할 수 있게 한다. 또한 애플리케이션이 컴파일된 당시 존재하지 않았던 장치에서 애플리케이션을 실행할 수 있는 유일한 방법이기도 하다(<a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#application-compatibility">애플리케이션 호환성</a>에서 자세히 설명).</p>
<p>디바이스 드라이버가 일부 애플리케이션에 대한 일부 PTX 코드를 JIT 컴파일할 때, 이후 애플리케이션 호출에서 컴파일을 반복하지 않기 위해 생성된 바이너리 코드의 사본을 자동으로 캐시한다. 캐시(컴퓨트 캐시라고 함)는 장치 드라이버가 업그레이드될 때 자동으로 무효화되므로 애플리케이션은 장치 드라이버에 내장된 새로운 JIT 컴파일러의 개선 사항을 활용 할 수 있다.</p>
<p>JIT 컴파일을 제어하는 환경 변수는 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#env-vars">CUDA 환경 변수</a>에 설명된 대로 ​​사용할 수 있다.</p>
<p><code>nvcc</code> 를 사용하여 CUDA C++ 장치 코드를 컴파일하는 대신 NVRTC를 사용하여 런타임에 CUDA C++ 장치 코드를 PTX로 컴파일할 수 있다. NVRTC는 CUDA C++용 런타임 컴파일 라이브러리이다. 자세한 내용은 NVRTC 사용자 가이드에서 확인할 수 있다.</p>
<p><br></p>
</section>
</section>
<section id="sec-cuda_binary_compatibility" class="level3" data-number="1.2">
<h3 data-number="1.2" class="anchored" data-anchor-id="sec-cuda_binary_compatibility"><span class="header-section-number">1.2</span> 바이너리 호환성</h3>
<p>바이너리 코드는 아키텍처에 따라 다르다. cubin 객체는 <code>-code</code> 컴파일러 옵션을 사용하여 대상 아키텍처를 지정하여 생성된다. 예를 들어, <code>-code=sm_80</code> 으로 컴파일하면 compute capability 8.0의 장치에 대한 바이너리 코드가 생성된다. 바이너리 호환성은 한 마이너 리비전에서 다음 리비전으로 보장되지만, 한 마이너 리비전에서 이전 리비전으로 또는 주요 리비전 간에는 보장되지 않는다. 즉, compute capability X.y에 대해 생성된 cubin 객체는 z≥y인 컴퓨팅 기능 X.z의 장치에서만 실행된다.</p>
<p><br></p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
경고
</div>
</div>
<div class="callout-body-container callout-body">
<p>바이너리 호환성은 데스크톱에서만 지원되며 Tegra에서는 지원되지 않는다. 또한 데스크톱과 Tegra 간의 바이너리 호환성도 지원되지 않는다.</p>
</div>
</div>
<p><br></p>
</section>
<section id="sec-cuda_ptx_compatibility" class="level3" data-number="1.3">
<h3 data-number="1.3" class="anchored" data-anchor-id="sec-cuda_ptx_compatibility"><span class="header-section-number">1.3</span> PTX 호환성</h3>
<p>일부 PTX 명령어는 고성능 장치에서만 지원된다. 예를 들어, <code>Warp Shuffle</code>(https://docs.nvidia.com/cuda/cuda-c-programming-guide/#warp-shuffle-functions) 함수는 compute capability 5.0 이상의 장치에서만 지원된다. <code>-arch</code> 컴파일러 옵션은 C++를 PTX 코드로 컴파일할 때 가정하는 compute capability 를 지정한다. 따라서 예를 들어 Warp Shuffle이 포함된 코드는 <code>-arch=compute_50</code> (또는 그 이상)으로 컴파일해야 한다.</p>
<p>특정 compute capability 를 위해 생성된 PTX 코드는 항상 더 크거나 같은 컴퓨팅 기능의 바이너리 코드로 컴파일할 수 있다. 이전 PTX 버전에서 컴파일된 바이너리는 일부 하드웨어 기능을 사용하지 못할 수 있다. 예를 들어, compute capability 6.0(Pascal)을 위해 생성된 PTX에서 컴파일된 compute capability 7.0(Volta) 장치를 대상으로 하는 바이너리는 Pascal에서 사용할 수 없는 Tensor Core 명령어를 사용하지 않는다. 결과적으로 최종 바이너리는 최신 버전의 PTX를 사용하여 바이너리를 생성한 경우보다 성능이 떨어질 수 있다.</p>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#feature-availability">아키텍처 조건부 기능</a>을 대상으로 컴파일된 PTX 코드는 정확히 동일한 물리적 아키텍처에서만 실행되고 다른 곳에서는 실행되지 않는다. 아치텍쳐 조건부 PTX 코드는 이전 혹은 이후와 호환되지 않는다. <code>sm_90a</code> 또는 <code>compute_90a</code> 로 컴파일된 예제 코드는 compute capability 9.0 이 있는 장치에서만 실행되며 이전 혹은 이후와 호환되지 않는다.</p>
<p><br></p>
</section>
<section id="sec-cuda_application_compatibility" class="level3" data-number="1.4">
<h3 data-number="1.4" class="anchored" data-anchor-id="sec-cuda_application_compatibility"><span class="header-section-number">1.4</span> 응용 프로그램 호환성</h3>
<p>특정 compute capability 의 장치에서 코드를 실행하려면 애플리케이션은 바이너리 호환성 및 PTX 호환성에서 설명한 대로 이 compute capability 과 호환되는 바이너리 또는 PTX 코드를 로드해야 한다. 특히, 더 높은 컴퓨팅 기능을 갖춘 미래 아키텍처에서 코드를 실행하려면(아직 바이너리 코드를 생성할 수 없는 경우) 애플리케이션은 이러한 장치에 대해 JIT 컴파일되는 PTX 코드를 로드해야 한다.(<a href="#sec-cuda_jit_compilation">JIT 컴파일</a> 참조).</p>
<p>CUDA C++ 애플리케이션에 어떤 PTX와 바이너리 코드가 포함되는지는 <code>nvcc</code> 사용자 매뉴얼에 자세히 설명된 대로 <code>-arch</code> 및 <code>-code</code> 컴파일러 옵션 또는 <code>-gencode</code> 컴파일러 옵션에 의해 제어된다. 예를 들어보자.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode txt code-with-copy"><code class="sourceCode default"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>nvcc x.cu</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>        -gencode arch=compute_50,code=sm_50</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        -gencode arch=compute_60,code=sm_60</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        -gencode arch=compute_70,code=\"compute_70,sm_70\"</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>위의 컴파일은 compute capability 5.0 및 6.0(첫 번째 및 두 번째 <code>-gencode</code> 옵션)과 호환되는 바이너리 코드와 compute capability 7.0(세 번째 <code>-gencode</code> 옵션)과 호환되는 PTX 및 바이너리 코드를 embeds 한다.</p>
<p>호스트 코드는 런타임에 로드하고 실행할 가장 적합한 코드를 자동으로 선택하도록 생성된다. 위의 예에서 이는 다음과 같다.</p>
<ul>
<li>compute capability 5.0 및 5.2가 있는 장치의 경우 5.0 바이너리 코드,</li>
<li>compute capability 6.0 및 6.1이 있는 장치의 경우 6.0 바이너리 코드,</li>
<li>compute capability 7.0 및 7.5가 있는 장치의 경우 7.0 바이너리 코드,</li>
<li>compute capability 8.0 및 8.6이 있는 장치의 경우 런타임에 바이너리 코드로 컴파일되는 PTX 코드.</li>
</ul>
<p><br></p>
<p><code>x.cu</code> 는 예를 들어, 워프 감소 연산을 사용하는 최적화된 코드 경로를 가질 수 있으며, 이는 compute capability 8.0 이상의 장치에서만 지원된다. <code>__CUDA_ARCH__</code> 매크로는 compute capability 에 따라 다양한 코드 경로를 구분하는 데 사용할 수 있다. 이는 장치 코드에 대해서만 정의된다. 예를 들어 <code>-arch=compute_80</code> 으로 컴파일할 때 <code>__CUDA_ARCH__</code> 는 <code>800</code> 과 같다.</p>
<p><code>x.cu</code> 가 <code>sm_90a</code> 또는 <code>compute_90a</code> 를 사용하여 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#feature-availability">아키텍처 조건부 기능</a> 예제에 대해 컴파일된 경우, 코드는 compute capability 9.0이 있는 장치에서만 실행할 수 있다.</p>
<p>드라이버 API를 사용하는 애플리케이션은 코드를 컴파일하여 파일을 분리하고 런타임에 가장 적합한 파일을 명시적으로 로드하여 실행해야 한다.</p>
<p>Volta 아키텍처는 GPU에서 스레드가 예약되는 방식을 변경하는 독립 스레드 스케줄링을 도입합니다. 이전 아키텍처에서 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#simt-architecture">SIMT 스케줄링</a> 의 특정 동작에 의존하는 코드의 경우 독립 스레드 스케줄링은 참여 스레드 세트를 변경하여 잘못된 결과를 초래할 수 있다. <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#independent-thread-scheduling-7-x">Independent Thread Scheduling</a> 에서 자세히 설명한 시정 조치를 구현하는 동안 마이그레이션을 지원하기 위해 Volta 개발자는 컴파일러 옵션 조합 <code>-arch=compute_60  -code=sm_70</code>을 사용하여 Pascal의 스레드 스케줄링을 선택할 수 있습니다.</p>
<p><code>nvcc</code> 사용자 설명서에는 <code>-arch</code>, <code>-code</code> 및 <code>-gencode</code> 컴파일러 옵션에 대한 다양한 약어가 나와 있다. 예를 들어, <code>-arch=sm_70</code> 은 <code>-arch=compute_70 -code=compute_70,sm_70</code> (<code>-gencode arch=compute_70,code=\"compute_70,sm_70\"</code> 과 동일)의 약어입니다.</p>
<p><br></p>
</section>
<section id="sec-cuda_cpp_compatibility" class="level3" data-number="1.5">
<h3 data-number="1.5" class="anchored" data-anchor-id="sec-cuda_cpp_compatibility"><span class="header-section-number">1.5</span> C++ 호환성</h3>
<p>컴파일러의 프런트 엔드는 C++ 구문 규칙에 따라 CUDA 소스 파일을 처리합니다. 호스트 코드에는 전체 C++가 지원된다. 그러나 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#c-cplusplus-language-support">C++ 언어 지원</a> 에 설명된 대로 C++의 하위 집합만 장치 코드에 대해 완전히 지원된다.</p>
<p><br></p>
</section>
<section id="sec-cuda_64bit_compatibility" class="level3" data-number="1.6">
<h3 data-number="1.6" class="anchored" data-anchor-id="sec-cuda_64bit_compatibility"><span class="header-section-number">1.6</span> 64 비트 호환성</h3>
<p><code>nvcc</code>의 64비트 버전은 64비트 모드에서 디바이스 코드를 컴파일한다(즉, 포인터는 64비트이다). 64비트 모드에서 컴파일된 디바이스 코드는 64비트 모드에서 컴파일된 호스트 코드에서만 지원된다.</p>
</section>
</section>
<section id="cuda-runtime" class="level2" data-number="2">
<h2 data-number="2" class="anchored" data-anchor-id="cuda-runtime"><span class="header-section-number">2</span> CUDA Runtime</h2>
<p>런타임은 <code>cudart</code> 라이브러리에서 구현되며, <code>cudart.lib</code> 또는 <code>libcudart.a</code> 를 통해 정적으로 또는 <code>cudart.dll</code> 또는 <code>libcudart.so</code> 를 통해 동적으로 응용프로그램에 링크된다. 동적 링크에 <code>cudart.dll</code> 및/또는 <code>cudart.so</code> 가 필요한 애플리케이션은 일반적으로 이를 애플리케이션 설치 패키지의 일부로 포함한다. CUDA 런타임 심볼의 주소는 CUDA 런타임의 동일한 인스턴스에 링크하는 구성 요소 사이에서만 안전하게 전달할 수 있다.</p>
<p>모든 진입점에는 <code>cuda</code> 라는 접두사가 붙습니다.</p>
<p><a href="../../../src/gpu/cuda/02_programming_model.html#sec-cuda_heterogeneous_programming">이기종 프로그래밍(Heterogeneous Programming)</a> 에서 언급했듯이 CUDA 프로그래밍 모델은 각각 별도의 메모리가 있는 호스트와 디바이스로 구성된 시스템을 가정한다. <a href="#sec-cuda_device_memory">장치 메모리</a> 에서 장치 메모리를 관리하는 데 사용되는 런타임 함수에 대해 소개한다.</p>
<p><a href="#sec-cuda_shared_memory">공유 메모리</a> 에서 스레드 계층에서 도입된 공유 메모리를 사용하여 성능을 극대화하는 방법을 보인다.</p>
<p><a href="#sec-cuda_page_locked_host_meory">페이지 잠금 호스트 메모리</a> 에서는 호스트와 장치 메모리 간의 데이터 전송과 커널 실행을 겹치게 하는 데 필요한 페이지 잠금 호스트 메모리를 소개한다.</p>
<p><a href="#sec-cuda_asynchronous_concurrent_execution">비동기 동시 실행</a> 에서는 시스템의 다양한 수준에서 비동기 동시 실행을 가능하게 하는 데 사용되는 개념과 API를 설명한다.</p>
<p><a href="#sec-cuda_multi_device_system">다중 디바이스 시스템</a> 에서는 프로그래밍 모델이 동일한 호스트에 연결된 여러 장치가 있는 시스템으로 확장되는 방식을 보여준다.</p>
<p><a href="#sec-cuda_error_checking">오류 검사</a> 에서는 런타임에서 생성된 오류를 올바르게 검사하는 방법을 설명한다.</p>
<p><a href="#sec-cuda_call_stack">호출 스택</a> 은 CUDA C++ 호출 스택을 관리하는 데 사용되는 런타임 함수를 소개한다.</p>
<p><a href="#sec-cuda_texture_and_surface_memory">텍스처 및 표면 메모리</a> 에서는 장치 메모리에 액세스하는 또 다른 방법을 제공하는 텍스처 및 표면 메모리 공간을 설명한다. 또한 GPU 텍스처링 하드웨어의 하위 집합을 보여준다.</p>
<p><a href="#sec-cuda_graphics_interoperability">그래픽 상호 운용성</a> 은 런타임이 두 가지 주요 그래픽 API인 OpenGL 및 Direct3D 와 상호 운용하기 위해 제공하는 다양한 함수를 소개한다</p>
<p><br></p>
<section id="sec-cuda_initialization" class="level3" data-number="2.1">
<h3 data-number="2.1" class="anchored" data-anchor-id="sec-cuda_initialization"><span class="header-section-number">2.1</span> 초기화</h3>
<p>CUDA 12.0부터 <code>cudaInitDevice()</code> 및 <code>cudaSetDevice()</code> 를 호출하면 지정된 디바이스와 연관된 런타임 및 기본 컨텍스트를 초기화합니다. 이러한 호출이 없으면 런타임은 암묵적으로 Device 0 을 사용하고 필요에 따라 자체로 초기화하여 다른 런타임 API 요청을 처리합니다. 런타임 함수 호출의 타이밍을 지정하고 첫 번째 호출의 오류 코드를 런타임으로 해석할 때 이 점을 염두에 두어야 합니다. 12.0 이전에는 <code>cudaSetDevice()</code> 가 런타임을 초기화하지 않았고 애플리케이션은 종종 no-op 런타임 호출 <code>cudaFree(0)</code> 를 사용하여 런타임 초기화를 다른 API 활동에서 분리했습니다(타이밍과 오류 처리를 위해).</p>
<p>런타임은 시스템의 각 장치에 대한 CUDA 컨텍스트를 만듭니다(CUDA 컨텍스트에 대한 자세한 내용은 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#context">컨텍스트</a> 참조). 이 컨텍스트는 이 디바이스의 기본 컨텍스트이며 이 디바이스 에서 활성 컨텍스트가 필요한 첫 번째 런타임 함수에서 초기화됩니다. 이 컨텍스트는 애플리케이션의 모든 호스트 스레드에서 공유됩니다. 이 컨텍스트 생성의 일부로, 필요한 경우 디바이스 코드가 <a href="#sec-cuda_jit_compilation">JIT 컴파일</a> 되고 디바이스 메모리에 로드됩니다. 이 모든 것이 투명하게 이루어집니다. 예를 들어 드라이버 API 상호 운용성을 위해 필요한 경우 디바이스의 기본 컨텍스트는 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#interoperability-between-runtime-and-driver-apis">런타임 및 드라이버 API 간 상호 운용성</a>에 설명된 대로 드라이버 API에서 액세스할 수 있습니다.</p>
<p>호스트 스레드가 <code>cudaDeviceReset()</code> 을 호출하면 호스트 스레드가 현재 작동하는 디바이스의 기본 컨텍스트(즉, <a href="#sec-cuda-device_selection">디바이스 선택</a>에서 정의된 현재 디바이스)가 파괴됩니다. 이 디바이스를 현재 디바이스로 갖는 호스트 스레드가 다음에 호출하는 런타임 함수는 이 장치에 대한 새 기본 컨텍스트를 생성합니다.</p>
<p><br></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
노트
</div>
</div>
<div class="callout-body-container callout-body">
<p>CUDA 인터페이스는 호스트 프로그램 시작 중에 초기화되고 호스트 프로그램 종료 중에 파괴되는 전역 상태를 사용합니다. CUDA 런타임과 드라이버는 이 상태가 유효하지 않은지 감지할 수 없으므로 main) 이후 프로그램 시작 또는 종료 중에 이러한 인터페이스 중 하나를 명시적으로든 암묵적으로든 사용하면 정의되지 않은 동작이 발생합니다.</p>
<p>CUDA 12.0부터 <code>cudaSetDevice()</code> 는 이제 호스트 스레드에 대한 현재 장치를 변경한 후 런타임을 명시적으로 초기화합니다. 이전 버전의 CUDA는 <code>cudaSetDevice()</code> 이후 첫 번째 런타임 호출이 이루어질 때까지 새 장치에서 런타임 초기화를 지연했습니다. 이 변경으로 인해 이제 초기화 오류에 대해 <code>cudaSetDevice()</code> 의 반환값을 확인하는 것이 매우 중요합니다.</p>
<p>참조 매뉴얼의 오류 처리 및 버전 관리 섹션의 런타임 함수는 런타임을 초기화하지 않습니다.</p>
</div>
</div>
<p><br></p>
</section>
<section id="sec-cuda_device_memory" class="level3" data-number="2.2">
<h3 data-number="2.2" class="anchored" data-anchor-id="sec-cuda_device_memory"><span class="header-section-number">2.2</span> 장치 메모리</h3>
<p>이기종 프로그래밍에서 언급했듯이 CUDA 프로그래밍 모델은 각각 별도의 메모리를 가진 호스트와 디바이스로 구성된 시스템을 가정합니다. 커널은 디바이스 메모리에서 작동하므로 런타임은 디바이스 메모리를 할당, 할당 해제, 복사하고 호스트 메모리와 디바이스 메모리 간에 데이터를 전송하는 기능을 제공합니다.</p>
<p>디바이스 메모리는 선형 메모리(Linear meomry - ?) 또는 CUDA 배열로 할당할 수 있습니다.</p>
<p>CUDA 배열은 텍스처 페칭에 최적화된 불투명 메모리 레이아웃입니다. <a href="#sec-cuda_texture_and_surface_memory">텍스처 및 표면 메모리</a>에서 설명합니다.</p>
<p>선형 메모리는 단일 통합 주소 공간에 할당되므로 별도로 할당된 개체 예를 들어 이진 트리(binary tree) 또는 연결 리스트(linked list) 내에서 포인터를 통해 서로를 참조할 수 있습니다. 주소 공간의 크기는 호스트 시스템(CPU)과 사용된 GPU의 컴퓨팅 기능에 따라 달라집니다.</p>
<p><br></p>
<div id="tbl-cuda_linear_memory_address_space" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-cuda_linear_memory_address_space-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
표&nbsp;1: Linear Memory Address Space
</figcaption>
<div aria-describedby="tbl-cuda_linear_memory_address_space-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 71%">
<col style="width: 9%">
<col style="width: 9%">
<col style="width: 9%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: center;">x86_64 (AMD64)</th>
<th style="text-align: center;">POWER (ppc64le)</th>
<th style="text-align: center;">ARM64</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">up to compute capability 5.3 (Maxwell)</td>
<td style="text-align: center;">40bit</td>
<td style="text-align: center;">40bit</td>
<td style="text-align: center;">40bit</td>
</tr>
<tr class="even">
<td style="text-align: left;">compute capability 6.0 (Pascal) or newer</td>
<td style="text-align: center;">up to 47bit</td>
<td style="text-align: center;">up to 49bit</td>
<td style="text-align: center;">up to 48bit</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p><br></p>
<p>선형 메모리는 일반적으로 <code>cudaMalloc()</code> 를 사용하여 할당하고 <code>cudaFree()</code> 를 사용하여 해제하며 호스트 메모리와 장치 메모리 간의 데이터 전송은 일반적으로 <code>cudaMemcpy()</code> 를 사용하여 수행됩니다. 커널의 벡터 추가 코드 샘플에서 벡터는 호스트 메모리에서 장치 메모리로 복사해야 합니다.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#</span><span class="er">| code-fold: true</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#</span><span class="er">| code-summary: "Show the code"</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">// Device code</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> VecAdd<span class="op">(</span><span class="dt">float</span><span class="op">*</span> A<span class="op">,</span> <span class="dt">float</span><span class="op">*</span> B<span class="op">,</span> <span class="dt">float</span><span class="op">*</span> C<span class="op">,</span> <span class="dt">int</span> N<span class="op">)</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> i <span class="op">=</span> blockDim<span class="op">.</span>x <span class="op">*</span> blockIdx<span class="op">.</span>x <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>i <span class="op">&lt;</span> N<span class="op">)</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        C<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> A<span class="op">[</span>i<span class="op">]</span> <span class="op">+</span> B<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">// Host code</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> main<span class="op">()</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> N <span class="op">=</span> <span class="op">...;</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    <span class="dt">size_t</span> size <span class="op">=</span> N <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">);</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Allocate input vectors h_A and h_B in host memory</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> h_A <span class="op">=</span> <span class="op">(</span><span class="dt">float</span><span class="op">*)</span>malloc<span class="op">(</span>size<span class="op">);</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> h_B <span class="op">=</span> <span class="op">(</span><span class="dt">float</span><span class="op">*)</span>malloc<span class="op">(</span>size<span class="op">);</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> h_C <span class="op">=</span> <span class="op">(</span><span class="dt">float</span><span class="op">*)</span>malloc<span class="op">(</span>size<span class="op">);</span></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Initialize input vectors</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>    <span class="op">...</span></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Allocate vectors in device memory</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> d_A<span class="op">;</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_A<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> d_B<span class="op">;</span></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_B<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> d_C<span class="op">;</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_C<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Copy vectors from host memory to device memory</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>d_A<span class="op">,</span> h_A<span class="op">,</span> size<span class="op">,</span> cudaMemcpyHostToDevice<span class="op">);</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>d_B<span class="op">,</span> h_B<span class="op">,</span> size<span class="op">,</span> cudaMemcpyHostToDevice<span class="op">);</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Invoke kernel</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> threadsPerBlock <span class="op">=</span> <span class="dv">256</span><span class="op">;</span></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> blocksPerGrid <span class="op">=</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>            <span class="op">(</span>N <span class="op">+</span> threadsPerBlock <span class="op">-</span> <span class="dv">1</span><span class="op">)</span> <span class="op">/</span> threadsPerBlock<span class="op">;</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>    VecAdd<span class="op">&lt;&lt;&lt;</span>blocksPerGrid<span class="op">,</span> threadsPerBlock<span class="op">&gt;&gt;&gt;(</span>d_A<span class="op">,</span> d_B<span class="op">,</span> d_C<span class="op">,</span> N<span class="op">);</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Copy result from device memory to host memory</span></span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="co">// h_C contains the result in host memory</span></span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>h_C<span class="op">,</span> d_C<span class="op">,</span> size<span class="op">,</span> cudaMemcpyDeviceToHost<span class="op">);</span></span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Free device memory</span></span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_A<span class="op">);</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_B<span class="op">);</span></span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_C<span class="op">);</span></span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Free host memory</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>    <span class="op">...</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>선형 메모리는 <code>cudaMallocPitch()</code> 및 <code>cudaMalloc3D()</code> 를 통해 할당할 수도 있습니다. 이러한 함수는 2D 또는 3D 배열의 할당에 권장되며, <a href="#sec-cuda_device_memory_access">디바이스 메모리 액세스</a>에서 설명할 정렬 요구 사항을 충족하도록 할당이 적절하게 패딩되어 행 주소에 액세스하거나 2D 배열과 장치 메모리의 다른 영역 간에 복사를 수행할 때 최상의 성능을 보장합니다(<code>cudaMemcpy2D()</code> 및 <code>cudaMemcpy3D()</code> 함수 사용). 반환된 피치(또는 스트라이드)는 배열 요소에 접근하는 데 사용해야 합니다. 다음 코드 샘플은 부동 소수점 값의 너비 x 높이 2D 배열을 할당하고 장치 코드에서 배열 요소를 반복하는 방법을 보여줍니다.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Host code</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> width <span class="op">=</span> <span class="dv">64</span><span class="op">,</span> height <span class="op">=</span> <span class="dv">64</span><span class="op">;</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="dt">float</span><span class="op">*</span> devPtr<span class="op">;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="dt">size_t</span> pitch<span class="op">;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>cudaMallocPitch<span class="op">(&amp;</span>devPtr<span class="op">,</span> <span class="op">&amp;</span>pitch<span class="op">,</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>                width <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">),</span> height<span class="op">);</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>MyKernel<span class="op">&lt;&lt;&lt;</span><span class="dv">100</span><span class="op">,</span> <span class="dv">512</span><span class="op">&gt;&gt;&gt;(</span>devPtr<span class="op">,</span> pitch<span class="op">,</span> width<span class="op">,</span> height<span class="op">);</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">// Device code</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> MyKernel<span class="op">(</span><span class="dt">float</span><span class="op">*</span> devPtr<span class="op">,</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>                         <span class="dt">size_t</span> pitch<span class="op">,</span> <span class="dt">int</span> width<span class="op">,</span> <span class="dt">int</span> height<span class="op">)</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> r <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> r <span class="op">&lt;</span> height<span class="op">;</span> <span class="op">++</span>r<span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="dt">float</span><span class="op">*</span> row <span class="op">=</span> <span class="op">(</span><span class="dt">float</span><span class="op">*)((</span><span class="dt">char</span><span class="op">*)</span>devPtr <span class="op">+</span> r <span class="op">*</span> pitch<span class="op">);</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> c <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> c <span class="op">&lt;</span> width<span class="op">;</span> <span class="op">++</span>c<span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            <span class="dt">float</span> element <span class="op">=</span> row<span class="op">[</span>c<span class="op">];</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="op">}</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br> 다음 코드 샘플은 부동 소수점 값의 너비 x 높이 x 깊이 3D 배열을 할당하고 장치 코드에서 배열 요소를 반복하는 방법을 보여줍니다.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Host code</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="dt">int</span> width <span class="op">=</span> <span class="dv">64</span><span class="op">,</span> height <span class="op">=</span> <span class="dv">64</span><span class="op">,</span> depth <span class="op">=</span> <span class="dv">64</span><span class="op">;</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>cudaExtent extent <span class="op">=</span> make_cudaExtent<span class="op">(</span>width <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">),</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>                                    height<span class="op">,</span> depth<span class="op">);</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>cudaPitchedPtr devPitchedPtr<span class="op">;</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>cudaMalloc3D<span class="op">(&amp;</span>devPitchedPtr<span class="op">,</span> extent<span class="op">);</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>MyKernel<span class="op">&lt;&lt;&lt;</span><span class="dv">100</span><span class="op">,</span> <span class="dv">512</span><span class="op">&gt;&gt;&gt;(</span>devPitchedPtr<span class="op">,</span> width<span class="op">,</span> height<span class="op">,</span> depth<span class="op">);</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">// Device code</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> MyKernel<span class="op">(</span>cudaPitchedPtr devPitchedPtr<span class="op">,</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>                         <span class="dt">int</span> width<span class="op">,</span> <span class="dt">int</span> height<span class="op">,</span> <span class="dt">int</span> depth<span class="op">)</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    <span class="dt">char</span><span class="op">*</span> devPtr <span class="op">=</span> devPitchedPtr<span class="op">.</span>ptr<span class="op">;</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    <span class="dt">size_t</span> pitch <span class="op">=</span> devPitchedPtr<span class="op">.</span>pitch<span class="op">;</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>    <span class="dt">size_t</span> slicePitch <span class="op">=</span> pitch <span class="op">*</span> height<span class="op">;</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> z <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> z <span class="op">&lt;</span> depth<span class="op">;</span> <span class="op">++</span>z<span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        <span class="dt">char</span><span class="op">*</span> slice <span class="op">=</span> devPtr <span class="op">+</span> z <span class="op">*</span> slicePitch<span class="op">;</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> y <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> y <span class="op">&lt;</span> height<span class="op">;</span> <span class="op">++</span>y<span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>            <span class="dt">float</span><span class="op">*</span> row <span class="op">=</span> <span class="op">(</span><span class="dt">float</span><span class="op">*)(</span>slice <span class="op">+</span> y <span class="op">*</span> pitch<span class="op">);</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> x <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> x <span class="op">&lt;</span> width<span class="op">;</span> <span class="op">++</span>x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>                <span class="dt">float</span> element <span class="op">=</span> row<span class="op">[</span>x<span class="op">];</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>            <span class="op">}</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        <span class="op">}</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
노트
</div>
</div>
<div class="callout-body-container callout-body">
<p>너무 많은 메모리를 할당하여 시스템 전체 성능에 영향을 미치지 않도록 하려면 문제 크기에 따라 사용자에게 할당 매개변수를 요청하세요. 할당이 실패하면 다른 느린 메모리 유형(<code>cudaMallocHost()</code>, <code>cudaHostRegister()</code> 등)으로 폴백하거나 거부된 메모리가 얼마나 필요한지 알려주는 오류를 반환할 수 있습니다. 애플리케이션이 어떤 이유로 할당 매개변수를 요청할 수 없는 경우 이를 지원하는 플랫폼에 대해 <code>cudaMallocManaged()</code> 를 사용하는 것이 좋습니다.</p>
</div>
</div>
<p><br></p>
<p>참조 설명서에는 <code>cudaMalloc()</code> 로 할당된 선형 메모리, <code>cudaMallocPitch()</code> 또는 <code>cudaMalloc3D()</code> 로 할당된 선형 메모리, CUDA 배열, 전역 또는 상수 메모리 공간에서 선언된 변수에 할당된 메모리 간에 메모리를 복사하는 데 사용되는 다양한 함수가 모두 나열되어 있습니다.</p>
<p><br></p>
<p>다음 코드 샘플은 런타임 API를 통해 전역 변수에 액세스하는 다양한 방법을 보여줍니다.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>__constant__ <span class="dt">float</span> constData<span class="op">[</span><span class="dv">256</span><span class="op">];</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="dt">float</span> data<span class="op">[</span><span class="dv">256</span><span class="op">];</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>cudaMemcpyToSymbol<span class="op">(</span>constData<span class="op">,</span> data<span class="op">,</span> <span class="kw">sizeof</span><span class="op">(</span>data<span class="op">));</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>cudaMemcpyFromSymbol<span class="op">(</span>data<span class="op">,</span> constData<span class="op">,</span> <span class="kw">sizeof</span><span class="op">(</span>data<span class="op">));</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">float</span> devData<span class="op">;</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a><span class="dt">float</span> value <span class="op">=</span> <span class="fl">3.14</span><span class="bu">f</span><span class="op">;</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>cudaMemcpyToSymbol<span class="op">(</span>devData<span class="op">,</span> <span class="op">&amp;</span>value<span class="op">,</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">));</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">float</span><span class="op">*</span> devPointer<span class="op">;</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a><span class="dt">float</span><span class="op">*</span> ptr<span class="op">;</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>cudaMalloc<span class="op">(&amp;</span>ptr<span class="op">,</span> <span class="dv">256</span> <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">));</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>cudaMemcpyToSymbol<span class="op">(</span>devPointer<span class="op">,</span> <span class="op">&amp;</span>ptr<span class="op">,</span> <span class="kw">sizeof</span><span class="op">(</span>ptr<span class="op">));</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><code>cudaGetSymbolAddress()</code> 는 전역 메모리 공간에서 선언된 변수에 할당된 메모리를 가리키는 주소를 검색하는 데 사용됩니다. 할당된 메모리의 크기는 <code>cudaGetSymbolSize()</code> 를 통해 얻습니다.</p>
<p><br></p>
</section>
<section id="디바이스-메모리-l2-접근-관리" class="level3" data-number="2.3">
<h3 data-number="2.3" class="anchored" data-anchor-id="디바이스-메모리-l2-접근-관리"><span class="header-section-number">2.3</span> 디바이스 메모리 L2 접근 관리</h3>
<p>CUDA 커널이 전역 메모리의 데이터 영역에 반복적으로 액세스하는 경우 이러한 데이터 액세스는 지속되는 것으로 간주될 수 있습니다. 반면, 데이터가 한 번만 액세스되는 경우 이러한 데이터 액세스는 스트리밍으로 간주될 수 있습니다.</p>
<p>CUDA 11.0부터 컴퓨팅 기능 8.0 이상의 장치는 L2 캐시의 데이터 지속성에 영향을 미칠 수 있는 기능을 갖추고 있어 글로벌 메모리에 대한 더 높은 대역폭과 더 낮은 지연 시간 액세스를 제공할 수 있습니다.</p>
<p><br></p>
<section id="l2-cache-set-aside-for-persisting-accesses" class="level4">
<h4 class="anchored" data-anchor-id="l2-cache-set-aside-for-persisting-accesses">L2 Cache Set-Aside for Persisting Accesses</h4>
<p>L2 캐시의 일부는 전역 메모리에 대한 지속적인 데이터 액세스에 사용하도록 따로 보관할 수 있습니다. 지속적인 액세스는 L2 캐시의 이 따로 보관된 부분을 우선적으로 사용하지만, 글로벌 메모리에 대한 일반 또는 스트리밍 액세스는 지속적인 액세스에서 사용되지 않을 때만 L2의 이 부분을 활용할 수 있습니다.</p>
<p>지속적인 액세스를 위한 L2 캐시 예약 크기는 다음 한도 내에서 조정될 수 있습니다.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>cudaGetDeviceProperties<span class="op">(&amp;</span>prop<span class="op">,</span> device_id<span class="op">);</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="dt">size_t</span> size <span class="op">=</span> min<span class="op">(</span><span class="dt">int</span><span class="op">(</span>prop<span class="op">.</span>l2CacheSize <span class="op">*</span> <span class="fl">0.75</span><span class="op">),</span> prop<span class="op">.</span>persistingL2CacheMaxSize<span class="op">);</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>cudaDeviceSetLimit<span class="op">(</span>cudaLimitPersistingL2CacheSize<span class="op">,</span> size<span class="op">);</span> <span class="co">/* set-aside 3/4 of L2 cache for persisting accesses or the max allowed*/</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br></p>
<p>GPU가 Multi-Instance GPU(MIG) 모드로 구성된 경우 L2 캐시 예약 기능이 비활성화됩니다.</p>
<p>Multi-Process Service(MPS)를 사용하는 경우 L2 캐시 예약 크기는 <code>cudaDeviceSetLimit</code> 으로 변경할 수 없습니다. 대신 예약 크기는 환경 변수 <code>CUDA_DEVICE_DEFAULT_PERSISTING_L2_CACHE_PERCENTAGE_LIMIT</code> 를 통해 MPS 서버를 시작할 때만 지정할 수 있습니다.</p>
<p><br></p>
</section>
<section id="l2-policy-for-persisting-accesses" class="level4">
<h4 class="anchored" data-anchor-id="l2-policy-for-persisting-accesses">L2 Policy for Persisting Accesses</h4>
<p>access policy window 는 전역 메모리의 연속 영역과 해당 영역 내의 액세스에 대한 L2 캐시의 지속성 속성을 지정합니다. 아래 코드 예제는 CUDA 스트림을 사용하여 L2 persisting access window 를 설정하는 방법을 보여줍니다.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode txt code-with-copy"><code class="sourceCode default"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>#| code-overflow: scroll</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>cudaStreamAttrValue stream_attribute;                                         // Stream level attributes data structure</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>stream_attribute.accessPolicyWindow.base_ptr  = reinterpret_cast&lt;void*&gt;(ptr); // Global Memory data pointer</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>stream_attribute.accessPolicyWindow.num_bytes = num_bytes;                    // Number of bytes for persistence access.</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                                                                              // (Must be less than cudaDeviceProp::accessPolicyMaxWindowSize)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>stream_attribute.accessPolicyWindow.hitRatio  = 0.6;                          // Hint for cache hit ratio</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>stream_attribute.accessPolicyWindow.hitProp   = cudaAccessPropertyPersisting; // Type of access property on cache hit</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>stream_attribute.accessPolicyWindow.missProp  = cudaAccessPropertyStreaming;  // Type of access property on cache miss.</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>//Set the attributes to a CUDA stream of type cudaStream_t</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>cudaStreamSetAttribute(stream, cudaStreamAttributeAccessPolicyWindow, &amp;stream_attribute);</span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br> * to be done *</p>
<p><br></p>
</section>
</section>
<section id="sec-cuda_shared_memory" class="level3" data-number="2.4">
<h3 data-number="2.4" class="anchored" data-anchor-id="sec-cuda_shared_memory"><span class="header-section-number">2.4</span> 공유 메모리</h3>
<p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#variable-memory-space-specifiers">가변 메모리 공간 지정자</a> 에서 자세히 설명하겠지만 공유 메모리는 <code>__shared__</code> 메모리 공간 지정자를 사용하여 할당됩니다.</p>
<p><a href="../../../src/gpu/cuda/02_programming_model.html#sec-cuda_thread_hierarchy">스레드 계층 구조</a>에서 언급되고 <a href="#sec-cuda_shared_memory">공유 메모리</a>에서 자세히 설명된 대로 공유 메모리는 전역 메모리보다 훨씬 빠를 것으로 예상됩니다. 다음 행렬 곱셈 예제에서 보여지는 것처럼 스크래치패드 메모리(또는 소프트웨어 관리 캐시)로 사용하여 CUDA 블록에서 글로벌 메모리 액세스를 최소화할 수 있습니다.</p>
<p>다음 코드 샘플은 공유 메모리를 활용하지 않는 간단한 행렬 곱셈 구현입니다. 각 스레드는 A의 한 행과 B의 한 열을 읽고 C의 해당 요소를 계산합니다. 따라서 A는 글로벌 메모리에서 B.width 번 읽히고 B는 A.height 번 읽힙니다.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrices are stored in row-major order:</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="co">// M(row, col) = *(M.elements + row * M.width + col)</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="kw">typedef</span> <span class="kw">struct</span> <span class="op">{</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> width<span class="op">;</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> height<span class="op">;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> elements<span class="op">;</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="op">}</span> Matrix<span class="op">;</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">// Thread block size</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="pp">#define BLOCK_SIZE </span><span class="dv">16</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">// Forward declaration of the matrix multiplication kernel</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> MatMulKernel<span class="op">(</span><span class="at">const</span> Matrix<span class="op">,</span> <span class="at">const</span> Matrix<span class="op">,</span> Matrix<span class="op">);</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrix multiplication - Host code</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrix dimensions are assumed to be multiples of BLOCK_SIZE</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> MatMul<span class="op">(</span><span class="at">const</span> Matrix A<span class="op">,</span> <span class="at">const</span> Matrix B<span class="op">,</span> Matrix C<span class="op">)</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Load A and B to device memory</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    Matrix d_A<span class="op">;</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    d_A<span class="op">.</span>width <span class="op">=</span> A<span class="op">.</span>width<span class="op">;</span> d_A<span class="op">.</span>height <span class="op">=</span> A<span class="op">.</span>height<span class="op">;</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="dt">size_t</span> size <span class="op">=</span> A<span class="op">.</span>width <span class="op">*</span> A<span class="op">.</span>height <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">);</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_A<span class="op">.</span>elements<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>d_A<span class="op">.</span>elements<span class="op">,</span> A<span class="op">.</span>elements<span class="op">,</span> size<span class="op">,</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>               cudaMemcpyHostToDevice<span class="op">);</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>    Matrix d_B<span class="op">;</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>    d_B<span class="op">.</span>width <span class="op">=</span> B<span class="op">.</span>width<span class="op">;</span> d_B<span class="op">.</span>height <span class="op">=</span> B<span class="op">.</span>height<span class="op">;</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> B<span class="op">.</span>width <span class="op">*</span> B<span class="op">.</span>height <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">);</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_B<span class="op">.</span>elements<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>d_B<span class="op">.</span>elements<span class="op">,</span> B<span class="op">.</span>elements<span class="op">,</span> size<span class="op">,</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>               cudaMemcpyHostToDevice<span class="op">);</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Allocate C in device memory</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    Matrix d_C<span class="op">;</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>    d_C<span class="op">.</span>width <span class="op">=</span> C<span class="op">.</span>width<span class="op">;</span> d_C<span class="op">.</span>height <span class="op">=</span> C<span class="op">.</span>height<span class="op">;</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> C<span class="op">.</span>width <span class="op">*</span> C<span class="op">.</span>height <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">);</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_C<span class="op">.</span>elements<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Invoke kernel</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a>    dim3 dimBlock<span class="op">(</span>BLOCK_SIZE<span class="op">,</span> BLOCK_SIZE<span class="op">);</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>    dim3 dimGrid<span class="op">(</span>B<span class="op">.</span>width <span class="op">/</span> dimBlock<span class="op">.</span>x<span class="op">,</span> A<span class="op">.</span>height <span class="op">/</span> dimBlock<span class="op">.</span>y<span class="op">);</span></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>    MatMulKernel<span class="op">&lt;&lt;&lt;</span>dimGrid<span class="op">,</span> dimBlock<span class="op">&gt;&gt;&gt;(</span>d_A<span class="op">,</span> d_B<span class="op">,</span> d_C<span class="op">);</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Read C from device memory</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>C<span class="op">.</span>elements<span class="op">,</span> d_C<span class="op">.</span>elements<span class="op">,</span> size<span class="op">,</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a>               cudaMemcpyDeviceToHost<span class="op">);</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Free device memory</span></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_A<span class="op">.</span>elements<span class="op">);</span></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_B<span class="op">.</span>elements<span class="op">);</span></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_C<span class="op">.</span>elements<span class="op">);</span></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrix multiplication kernel called by MatMul()</span></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> MatMulKernel<span class="op">(</span>Matrix A<span class="op">,</span> Matrix B<span class="op">,</span> Matrix C<span class="op">)</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread computes one element of C</span></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>    <span class="co">// by accumulating results into Cvalue</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span> Cvalue <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> row <span class="op">=</span> blockIdx<span class="op">.</span>y <span class="op">*</span> blockDim<span class="op">.</span>y <span class="op">+</span> threadIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> col <span class="op">=</span> blockIdx<span class="op">.</span>x <span class="op">*</span> blockDim<span class="op">.</span>x <span class="op">+</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> e <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> e <span class="op">&lt;</span> A<span class="op">.</span>width<span class="op">;</span> <span class="op">++</span>e<span class="op">)</span></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a>        Cvalue <span class="op">+=</span> A<span class="op">.</span>elements<span class="op">[</span>row <span class="op">*</span> A<span class="op">.</span>width <span class="op">+</span> e<span class="op">]</span></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>                <span class="op">*</span> B<span class="op">.</span>elements<span class="op">[</span>e <span class="op">*</span> B<span class="op">.</span>width <span class="op">+</span> col<span class="op">];</span></span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a>    C<span class="op">.</span>elements<span class="op">[</span>row <span class="op">*</span> C<span class="op">.</span>width <span class="op">+</span> col<span class="op">]</span> <span class="op">=</span> Cvalue<span class="op">;</span></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><br></p>
<div id="fig-cuda_matrix_multiplication_without_shared_memory" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cuda_matrix_multiplication_without_shared_memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/matrix-multiplication-without-shared-memory.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cuda_matrix_multiplication_without_shared_memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
그림&nbsp;1: 공유메모리를 사용하지 않는 행렬곱
</figcaption>
</figure>
</div>
<p><br></p>
<p>다음 코드 샘플은 공유 메모리를 활용하는 행렬 곱셈의 구현입니다. 이 구현에서 각 스레드 블록은 C의 하나의 정사각 부분 행렬 Csub를 계산할 책임이 있고 블록 내의 각 스레드는 Csub의 하나의 요소를 계산할 책임이 있습니다. 그림 9에서 볼 수 있듯이 Csub는 두 개의 직사각형 행렬의 곱과 같습니다. 즉, Csub와 같은 행 인덱스를 갖는 (A.width, block_size) 차원의 A의 부분 행렬과 Csub와 같은 열 인덱스를 갖는 (block_size, A.width) 차원의 B의 부분 행렬입니다. 장치의 리소스에 맞추기 위해 이 두 직사각형 행렬은 필요한 만큼의 block_size 차원의 정사각 행렬로 나뉘고 Csub는 이러한 정사각 행렬의 곱의 합으로 계산됩니다. 이러한 각 곱은 먼저 하나의 스레드가 각 행렬의 한 요소를 로드하여 두 개의 해당 정사각 행렬을 전역 메모리에서 공유 메모리로 로드한 다음 각 스레드가 곱의 한 요소를 계산하여 수행됩니다. 각 스레드는 이들 각각의 곱의 결과를 레지스터에 누적하고, 완료되면 결과를 전역 메모리에 씁니다.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrices are stored in row-major order:</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="co">// M(row, col) = *(M.elements + row * M.stride + col)</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">typedef</span> <span class="kw">struct</span> <span class="op">{</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> width<span class="op">;</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> height<span class="op">;</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> stride<span class="op">;</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span><span class="op">*</span> elements<span class="op">;</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="op">}</span> Matrix<span class="op">;</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">// Get a matrix element</span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">float</span> GetElement<span class="op">(</span><span class="at">const</span> Matrix A<span class="op">,</span> <span class="dt">int</span> row<span class="op">,</span> <span class="dt">int</span> col<span class="op">)</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> A<span class="op">.</span>elements<span class="op">[</span>row <span class="op">*</span> A<span class="op">.</span>stride <span class="op">+</span> col<span class="op">];</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">// Set a matrix element</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>__device__ <span class="dt">void</span> SetElement<span class="op">(</span>Matrix A<span class="op">,</span> <span class="dt">int</span> row<span class="op">,</span> <span class="dt">int</span> col<span class="op">,</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>                           <span class="dt">float</span> value<span class="op">)</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>    A<span class="op">.</span>elements<span class="op">[</span>row <span class="op">*</span> A<span class="op">.</span>stride <span class="op">+</span> col<span class="op">]</span> <span class="op">=</span> value<span class="op">;</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co">// Get the BLOCK_SIZExBLOCK_SIZE sub-matrix Asub of A that is</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co">// located col sub-matrices to the right and row sub-matrices down</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co">// from the upper-left corner of A</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a> __device__ Matrix GetSubMatrix<span class="op">(</span>Matrix A<span class="op">,</span> <span class="dt">int</span> row<span class="op">,</span> <span class="dt">int</span> col<span class="op">)</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    Matrix Asub<span class="op">;</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>    Asub<span class="op">.</span>width    <span class="op">=</span> BLOCK_SIZE<span class="op">;</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>    Asub<span class="op">.</span>height   <span class="op">=</span> BLOCK_SIZE<span class="op">;</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>    Asub<span class="op">.</span>stride   <span class="op">=</span> A<span class="op">.</span>stride<span class="op">;</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>    Asub<span class="op">.</span>elements <span class="op">=</span> <span class="op">&amp;</span>A<span class="op">.</span>elements<span class="op">[</span>A<span class="op">.</span>stride <span class="op">*</span> BLOCK_SIZE <span class="op">*</span> row</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>                                         <span class="op">+</span> BLOCK_SIZE <span class="op">*</span> col<span class="op">];</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Asub<span class="op">;</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a><span class="co">// Thread block size</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a><span class="pp">#define BLOCK_SIZE </span><span class="dv">16</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a><span class="co">// Forward declaration of the matrix multiplication kernel</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> MatMulKernel<span class="op">(</span><span class="at">const</span> Matrix<span class="op">,</span> <span class="at">const</span> Matrix<span class="op">,</span> Matrix<span class="op">);</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrix multiplication - Host code</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrix dimensions are assumed to be multiples of BLOCK_SIZE</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> MatMul<span class="op">(</span><span class="at">const</span> Matrix A<span class="op">,</span> <span class="at">const</span> Matrix B<span class="op">,</span> Matrix C<span class="op">)</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Load A and B to device memory</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>    Matrix d_A<span class="op">;</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>    d_A<span class="op">.</span>width <span class="op">=</span> d_A<span class="op">.</span>stride <span class="op">=</span> A<span class="op">.</span>width<span class="op">;</span> d_A<span class="op">.</span>height <span class="op">=</span> A<span class="op">.</span>height<span class="op">;</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>    <span class="dt">size_t</span> size <span class="op">=</span> A<span class="op">.</span>width <span class="op">*</span> A<span class="op">.</span>height <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">);</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_A<span class="op">.</span>elements<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>d_A<span class="op">.</span>elements<span class="op">,</span> A<span class="op">.</span>elements<span class="op">,</span> size<span class="op">,</span></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>               cudaMemcpyHostToDevice<span class="op">);</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>    Matrix d_B<span class="op">;</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>    d_B<span class="op">.</span>width <span class="op">=</span> d_B<span class="op">.</span>stride <span class="op">=</span> B<span class="op">.</span>width<span class="op">;</span> d_B<span class="op">.</span>height <span class="op">=</span> B<span class="op">.</span>height<span class="op">;</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> B<span class="op">.</span>width <span class="op">*</span> B<span class="op">.</span>height <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">);</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_B<span class="op">.</span>elements<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>d_B<span class="op">.</span>elements<span class="op">,</span> B<span class="op">.</span>elements<span class="op">,</span> size<span class="op">,</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>    cudaMemcpyHostToDevice<span class="op">);</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Allocate C in device memory</span></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>    Matrix d_C<span class="op">;</span></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>    d_C<span class="op">.</span>width <span class="op">=</span> d_C<span class="op">.</span>stride <span class="op">=</span> C<span class="op">.</span>width<span class="op">;</span> d_C<span class="op">.</span>height <span class="op">=</span> C<span class="op">.</span>height<span class="op">;</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>    size <span class="op">=</span> C<span class="op">.</span>width <span class="op">*</span> C<span class="op">.</span>height <span class="op">*</span> <span class="kw">sizeof</span><span class="op">(</span><span class="dt">float</span><span class="op">);</span></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>    cudaMalloc<span class="op">(&amp;</span>d_C<span class="op">.</span>elements<span class="op">,</span> size<span class="op">);</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Invoke kernel</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    dim3 dimBlock<span class="op">(</span>BLOCK_SIZE<span class="op">,</span> BLOCK_SIZE<span class="op">);</span></span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a>    dim3 dimGrid<span class="op">(</span>B<span class="op">.</span>width <span class="op">/</span> dimBlock<span class="op">.</span>x<span class="op">,</span> A<span class="op">.</span>height <span class="op">/</span> dimBlock<span class="op">.</span>y<span class="op">);</span></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>    MatMulKernel<span class="op">&lt;&lt;&lt;</span>dimGrid<span class="op">,</span> dimBlock<span class="op">&gt;&gt;&gt;(</span>d_A<span class="op">,</span> d_B<span class="op">,</span> d_C<span class="op">);</span></span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Read C from device memory</span></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    cudaMemcpy<span class="op">(</span>C<span class="op">.</span>elements<span class="op">,</span> d_C<span class="op">.</span>elements<span class="op">,</span> size<span class="op">,</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>               cudaMemcpyDeviceToHost<span class="op">);</span></span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Free device memory</span></span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_A<span class="op">.</span>elements<span class="op">);</span></span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_B<span class="op">.</span>elements<span class="op">);</span></span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>    cudaFree<span class="op">(</span>d_C<span class="op">.</span>elements<span class="op">);</span></span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a><span class="co">// Matrix multiplication kernel called by MatMul()</span></span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a> __global__ <span class="dt">void</span> MatMulKernel<span class="op">(</span>Matrix A<span class="op">,</span> Matrix B<span class="op">,</span> Matrix C<span class="op">)</span></span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Block row and column</span></span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> blockRow <span class="op">=</span> blockIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> blockCol <span class="op">=</span> blockIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread block computes one sub-matrix Csub of C</span></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>    Matrix Csub <span class="op">=</span> GetSubMatrix<span class="op">(</span>C<span class="op">,</span> blockRow<span class="op">,</span> blockCol<span class="op">);</span></span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread computes one element of Csub</span></span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a>    <span class="co">// by accumulating results into Cvalue</span></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>    <span class="dt">float</span> Cvalue <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Thread row and column within Csub</span></span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> row <span class="op">=</span> threadIdx<span class="op">.</span>y<span class="op">;</span></span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> col <span class="op">=</span> threadIdx<span class="op">.</span>x<span class="op">;</span></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Loop over all the sub-matrices of A and B that are</span></span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>    <span class="co">// required to compute Csub</span></span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Multiply each pair of sub-matrices together</span></span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>    <span class="co">// and accumulate the results</span></span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> m <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> m <span class="op">&lt;</span> <span class="op">(</span>A<span class="op">.</span>width <span class="op">/</span> BLOCK_SIZE<span class="op">);</span> <span class="op">++</span>m<span class="op">)</span> <span class="op">{</span></span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Get sub-matrix Asub of A</span></span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>        Matrix Asub <span class="op">=</span> GetSubMatrix<span class="op">(</span>A<span class="op">,</span> blockRow<span class="op">,</span> m<span class="op">);</span></span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Get sub-matrix Bsub of B</span></span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>        Matrix Bsub <span class="op">=</span> GetSubMatrix<span class="op">(</span>B<span class="op">,</span> m<span class="op">,</span> blockCol<span class="op">);</span></span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Shared memory used to store Asub and Bsub respectively</span></span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>        __shared__ <span class="dt">float</span> As<span class="op">[</span>BLOCK_SIZE<span class="op">][</span>BLOCK_SIZE<span class="op">];</span></span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>        __shared__ <span class="dt">float</span> Bs<span class="op">[</span>BLOCK_SIZE<span class="op">][</span>BLOCK_SIZE<span class="op">];</span></span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Load Asub and Bsub from device memory to shared memory</span></span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Each thread loads one element of each sub-matrix</span></span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>        As<span class="op">[</span>row<span class="op">][</span>col<span class="op">]</span> <span class="op">=</span> GetElement<span class="op">(</span>Asub<span class="op">,</span> row<span class="op">,</span> col<span class="op">);</span></span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>        Bs<span class="op">[</span>row<span class="op">][</span>col<span class="op">]</span> <span class="op">=</span> GetElement<span class="op">(</span>Bsub<span class="op">,</span> row<span class="op">,</span> col<span class="op">);</span></span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Synchronize to make sure the sub-matrices are loaded</span></span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>        <span class="co">// before starting the computation</span></span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>        __syncthreads<span class="op">();</span></span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Multiply Asub and Bsub together</span></span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> e <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> e <span class="op">&lt;</span> BLOCK_SIZE<span class="op">;</span> <span class="op">++</span>e<span class="op">)</span></span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>            Cvalue <span class="op">+=</span> As<span class="op">[</span>row<span class="op">][</span>e<span class="op">]</span> <span class="op">*</span> Bs<span class="op">[</span>e<span class="op">][</span>col<span class="op">];</span></span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a>        <span class="co">// Synchronize to make sure that the preceding</span></span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>        <span class="co">// computation is done before loading two new</span></span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a>        <span class="co">// sub-matrices of A and B in the next iteration</span></span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>        __syncthreads<span class="op">();</span></span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a>    <span class="op">}</span></span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Write Csub to device memory</span></span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>    <span class="co">// Each thread writes one element</span></span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>    SetElement<span class="op">(</span>Csub<span class="op">,</span> row<span class="op">,</span> col<span class="op">,</span> Cvalue<span class="op">);</span></span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-cuda_matrix_multiplication_with_shared_memory" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-cuda_matrix_multiplication_with_shared_memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://docs.nvidia.com/cuda/cuda-c-programming-guide/_images/matrix-multiplication-with-shared-memory.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-cuda_matrix_multiplication_with_shared_memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
그림&nbsp;2: 공유메모리를 사용않는 행렬곱
</figcaption>
</figure>
</div>
<p><br></p>
</section>
<section id="sec-cuda_distributed_shared_memory" class="level3" data-number="2.5">
<h3 data-number="2.5" class="anchored" data-anchor-id="sec-cuda_distributed_shared_memory"><span class="header-section-number">2.5</span> 분산 공유 메모리</h3>
<p>compute capability 9.0에 도입된 스레드 블록 클러스터는 스레드 블록 클러스터의 스레드가 클러스터에 참여하는 모든 스레드 블록의 공유 메모리에 액세스할 수 있는 기능을 제공합니다. 이 분할된 공유 메모리를 분산 공유 메모리(distributed shared memory)라고 하며, 해당 주소 공간을 분산 공유 메모리 주소 공간이라고 합니다. 스레드 블록 클러스터에 속한 스레드는 주소가 로컬 스레드 블록에 속하는지 원격 스레드 블록에 속하는지에 관계없이 분산 주소 공간에서 읽거나 쓰거나 아토믹 연산을 수행할 수 있습니다. 커널이 분산 공유 메모리를 사용하든 사용하지 않든, 정적이든 동적이든 공유 메모리 크기 사양은 여전히 ​​스레드 블록당입니다. 분산 공유 메모리의 크기는 클러스터당 스레드 블록 수에 스레드 블록당 공유 메모리 크기를 곱한 값일 뿐입니다.</p>
<p>분산 공유 메모리의 데이터에 액세스하려면 모든 스레드 블록이 존재해야 합니다. 사용자는 <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/#cluster-group-cg">Cluster Group</a> API의 <code>cluster.sync()</code> 를 사용하여 모든 스레드 블록이 실행을 시작했는지 보장할 수 있습니다. 사용자는 또한 모든 분산 공유 메모리 작업이 스레드 블록이 종료되기 전에 수행되도록 해야 합니다. 예를 들어 원격 스레드 블록이 주어진 스레드 블록의 공유 메모리를 읽으려고 하는 경우 사용자는 원격 스레드 블록이 읽은 공유 메모리가 종료되기 전에 완료되었는지 확인해야 합니다.</p>
<p>CUDA는 분산 공유 메모리에 액세스하는 메커니즘을 제공하며, 애플리케이션은 이 기능을 활용하여 이점을 얻을 수 있습니다. 간단한 히스토그램 계산과 스레드 블록 클러스터를 사용하여 GPU에서 최적화하는 방법을 살펴보겠습니다. 히스토그램을 계산하는 표준적인 방법은 각 스레드 블록의 공유 메모리에서 계산을 수행한 다음 글로벌 메모리 아토믹을 수행하는 것입니다. 이 방법의 한계는 공유 메모리 용량입니다. 히스토그램 빈이 더 이상 공유 메모리에 맞지 않으면 사용자는 히스토그램을 직접 계산하고 따라서 글로벌 메모리의 아토믹을 계산해야 합니다. 분산 공유 메모리를 사용하면 CUDA는 중간 단계를 제공하며, 여기서 히스토그램 빈 크기에 따라 히스토그램을 공유 메모리, 분산 공유 메모리 또는 글로벌 메모리에서 직접 계산할 수 있습니다.</p>
<p>아래의 CUDA 커널 예제는 히스토그램 빈의 수에 따라 공유 메모리 또는 분산 공유 메모리에서 히스토그램을 계산하는 방법을 보여줍니다.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode cpp code-with-copy"><code class="sourceCode cpp"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;cooperative_groups.h&gt;</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">// Distributed Shared memory histogram kernel</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>__global__ <span class="dt">void</span> clusterHist_kernel<span class="op">(</span><span class="dt">int</span> <span class="op">*</span>bins<span class="op">,</span> <span class="at">const</span> <span class="dt">int</span> nbins<span class="op">,</span> <span class="at">const</span> <span class="dt">int</span> bins_per_block<span class="op">,</span> <span class="at">const</span> <span class="dt">int</span> <span class="op">*</span><span class="ex">__restrict__</span> input<span class="op">,</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>                                   <span class="dt">size_t</span> array_size<span class="op">)</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="op">{</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">extern</span> __shared__ <span class="dt">int</span> smem<span class="op">[];</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="kw">namespace</span> cg <span class="op">=</span> cooperative_groups<span class="op">;</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> tid <span class="op">=</span> cg<span class="op">::</span>this_grid<span class="op">().</span>thread_rank<span class="op">();</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Cluster initialization, size and calculating local bin offsets.</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  cg<span class="op">::</span>cluster_group cluster <span class="op">=</span> cg<span class="op">::</span>this_cluster<span class="op">();</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>  <span class="dt">unsigned</span> <span class="dt">int</span> clusterBlockRank <span class="op">=</span> cluster<span class="op">.</span>block_rank<span class="op">();</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> cluster_size <span class="op">=</span> cluster<span class="op">.</span>dim_blocks<span class="op">().</span>x<span class="op">;</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> threadIdx<span class="op">.</span>x<span class="op">;</span> i <span class="op">&lt;</span> bins_per_block<span class="op">;</span> i <span class="op">+=</span> blockDim<span class="op">.</span>x<span class="op">)</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    smem<span class="op">[</span>i<span class="op">]</span> <span class="op">=</span> <span class="dv">0</span><span class="op">;</span> <span class="co">//Initialize shared memory histogram to zeros</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  <span class="co">// cluster synchronization ensures that shared memory is initialized to zero in</span></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>  <span class="co">// all thread blocks in the cluster. It also ensures that all thread blocks</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>  <span class="co">// have started executing and they exist concurrently.</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>  cluster<span class="op">.</span>sync<span class="op">();</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> tid<span class="op">;</span> i <span class="op">&lt;</span> array_size<span class="op">;</span> i <span class="op">+=</span> blockDim<span class="op">.</span>x <span class="op">*</span> gridDim<span class="op">.</span>x<span class="op">)</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> ldata <span class="op">=</span> input<span class="op">[</span>i<span class="op">];</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Find the right histogram bin.</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> binid <span class="op">=</span> ldata<span class="op">;</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="op">(</span>ldata <span class="op">&lt;</span> <span class="dv">0</span><span class="op">)</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>      binid <span class="op">=</span> <span class="dv">0</span><span class="op">;</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> <span class="cf">if</span> <span class="op">(</span>ldata <span class="op">&gt;=</span> nbins<span class="op">)</span></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>      binid <span class="op">=</span> nbins <span class="op">-</span> <span class="dv">1</span><span class="op">;</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Find destination block rank and offset for computing</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>    <span class="co">//distributed shared memory histogram</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> dst_block_rank <span class="op">=</span> <span class="op">(</span><span class="dt">int</span><span class="op">)(</span>binid <span class="op">/</span> bins_per_block<span class="op">);</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> dst_offset <span class="op">=</span> binid <span class="op">%</span> bins_per_block<span class="op">;</span></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Pointer to target block shared memory</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>    <span class="dt">int</span> <span class="op">*</span>dst_smem <span class="op">=</span> cluster<span class="op">.</span>map_shared_rank<span class="op">(</span>smem<span class="op">,</span> dst_block_rank<span class="op">);</span></span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    <span class="co">//Perform atomic update of the histogram bin</span></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>    atomicAdd<span class="op">(</span>dst_smem <span class="op">+</span> dst_offset<span class="op">,</span> <span class="dv">1</span><span class="op">);</span></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a>  <span class="co">// cluster synchronization is required to ensure all distributed shared</span></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a>  <span class="co">// memory operations are completed and no thread block exits while</span></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a>  <span class="co">// other thread blocks are still accessing distributed shared memory</span></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>  cluster<span class="op">.</span>sync<span class="op">();</span></span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a>  <span class="co">// Perform global memory histogram, using the local distributed memory histogram</span></span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a>  <span class="dt">int</span> <span class="op">*</span>lbins <span class="op">=</span> bins <span class="op">+</span> cluster<span class="op">.</span>block_rank<span class="op">()</span> <span class="op">*</span> bins_per_block<span class="op">;</span></span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> <span class="op">(</span><span class="dt">int</span> i <span class="op">=</span> threadIdx<span class="op">.</span>x<span class="op">;</span> i <span class="op">&lt;</span> bins_per_block<span class="op">;</span> i <span class="op">+=</span> blockDim<span class="op">.</span>x<span class="op">)</span></span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>  <span class="op">{</span></span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>    atomicAdd<span class="op">(&amp;</span>lbins<span class="op">[</span>i<span class="op">],</span> smem<span class="op">[</span>i<span class="op">]);</span></span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a>  <span class="op">}</span></span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code><button title="클립보드 복사" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>위의 커널은 필요한 분산 공유 메모리 양에 따라 클러스터 크기로 런타임에 시작할 수 있습니다. 히스토그램이 한 블록의 공유 메모리에 맞을 만큼 작으면 사용자는 클러스터 크기 1로 커널을 시작할 수 있습니다. 아래 코드 조각은 공유 메모리 요구 사항에 따라 동적으로 클러스터 커널을 시작하는 방법을 보여줍니다.</p>
<p><br></p>
</section>
<section id="sec-cuda_page_locked_host_meory" class="level3" data-number="2.6">
<h3 data-number="2.6" class="anchored" data-anchor-id="sec-cuda_page_locked_host_meory"><span class="header-section-number">2.6</span> 페이지 잠금 호스트 메모리</h3>
</section>
<section id="sec-cuda_asynchronous_concurrent_execution" class="level3" data-number="2.7">
<h3 data-number="2.7" class="anchored" data-anchor-id="sec-cuda_asynchronous_concurrent_execution"><span class="header-section-number">2.7</span> 비동기 동시 실행 (Asynchronous concurrent Execution)</h3>
</section>
<section id="sec-cuda_multi_device_system" class="level3" data-number="2.8">
<h3 data-number="2.8" class="anchored" data-anchor-id="sec-cuda_multi_device_system"><span class="header-section-number">2.8</span> 다중 디바이스 시스템</h3>
<section id="sec-cuda-device_selection" class="level4">
<h4 class="anchored" data-anchor-id="sec-cuda-device_selection">디바이스 선택</h4>
</section>
</section>
<section id="sec-cuda_error_checking" class="level3" data-number="2.9">
<h3 data-number="2.9" class="anchored" data-anchor-id="sec-cuda_error_checking"><span class="header-section-number">2.9</span> 오류 검사</h3>
</section>
<section id="sec-cuda_call_stack" class="level3" data-number="2.10">
<h3 data-number="2.10" class="anchored" data-anchor-id="sec-cuda_call_stack"><span class="header-section-number">2.10</span> 호출 스택</h3>
</section>
<section id="sec-cuda_texture_and_surface_memory" class="level3" data-number="2.11">
<h3 data-number="2.11" class="anchored" data-anchor-id="sec-cuda_texture_and_surface_memory"><span class="header-section-number">2.11</span> 텍스쳐와 표면 메모리</h3>
</section>
<section id="sec-cuda_graphics_interoperability" class="level3" data-number="2.12">
<h3 data-number="2.12" class="anchored" data-anchor-id="sec-cuda_graphics_interoperability"><span class="header-section-number">2.12</span> 그래픽 상호 운용성</h3>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "복사완료!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "복사완료!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/julia-kaeri\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../../src/gpu/cuda/02_programming_model.html" class="pagination-link" aria-label="Programming Model">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Programming Model</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../../src/gpu/cuda.jl/cuda_jl_array_programming.html" class="pagination-link" aria-label="CUDA.jl 배열 처리">
        <span class="nav-page-text">CUDA.jl 배열 처리</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>